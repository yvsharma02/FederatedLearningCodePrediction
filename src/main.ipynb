{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_dim, head_size, context_window_len, mask):\n",
    "        super(AttentionHead, self).__init__()\n",
    "        # These Layers Map (B, W, E) -> (B, W, HEAD_SIZE)\n",
    "\n",
    "        assert mask == 'encoder' or mask == 'decoder'\n",
    "\n",
    "        self.key = nn.Linear(emb_dim, head_size, bias=False, device=device)\n",
    "        self.query = nn.Linear(emb_dim, head_size, bias=False, device=device)\n",
    "        self.value = nn.Linear(emb_dim, head_size, bias=False, device=device)\n",
    "        self.mask_type = mask\n",
    "        self.context_window_len = context_window_len\n",
    "        self.head_size = head_size\n",
    "\n",
    "    # Returns a mask of (W, W)\n",
    "    def get_mask_tensor(self):\n",
    "        if (self.mask_type == 'encoder'):\n",
    "            return torch.tril(torch.ones(self.context_window_len, self.context_window_len, device=device))\n",
    "        elif (self.mask_type == 'decoder'):\n",
    "            return torch.ones(self.context_window_len, self.context_window_len, device=device)\n",
    "    \n",
    "    # Input is of shape (B, W, E) where E is embedding dimensions.\n",
    "    # Output is of shape (B, W, E)\n",
    "    def forward(self, input):\n",
    "        k = self.key(input) # Convert (B, W1, E) -> (B, W1, HEAD_SIZE)\n",
    "        q = self.query(input) # Convert (B, W2, E) -> (B, W2, HEAD_SIZE) (W1 == W2 == W3)\n",
    "        v = self.value(input) # (B, W3, E) -> (B, W3, HEAD_SIZE)\n",
    "        match = q @ k.transpose(-2, -1) # Produce Matrix (B, W1, W2)\n",
    "        mask = self.get_mask_tensor()\n",
    "        match = match.masked_fill(mask == 0, float('-inf'))\n",
    "        attention = torch.softmax(match, dim=-1) / math.sqrt(self.head_size) # Still (B, W1, W2)\n",
    "\n",
    "        res = attention @ v # (B, W1, W2) @ (B, W3, HEAD_SIZE) -> (B, W1=W3, HEAD_SIZE)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_dim, num_heads, context_window_len, mask):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert emb_dim % num_heads == 0\n",
    "        self.attention_heads = [AttentionHead(emb_dim, emb_dim // num_heads, context_window_len, mask) for i in range(0, num_heads)]\n",
    "        \n",
    "\n",
    "    # Input is (B, W, E)\n",
    "    def forward(self, input):\n",
    "        # Each ah returns (B, W, E/num_heads)\n",
    "        return torch.cat([ah(input) for ah in self.attention_heads], dim= -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, context_window_size, embedding_dimensions, num_heads, hidden_layer_multiplier = 4, dropout_rate = 0.3):\n",
    "        super(Block, self).__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            MultiHeadedAttention(embedding_dimensions, num_heads, context_window_size, 'encoder'),\n",
    "            nn.Linear(embedding_dimensions, hidden_layer_multiplier * embedding_dimensions, device=device),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_dimensions * hidden_layer_multiplier, embedding_dimensions, device=device),\n",
    "            nn.LayerNorm(embedding_dimensions, device=device),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "    # Raw input is a tesnor of (B, W). It should have already mapped tokens to integer.\n",
    "    def forward(self, raw_input):\n",
    "        return self.network(raw_input)\n",
    "\n",
    "class CustomTransformer(nn.Module):\n",
    "\n",
    "    # Input to the Transformer will be a matrix of size (B, W)\n",
    "    # B is the Batch Size.\n",
    "    # W is the Window Size (context_window_size)\n",
    "    # Example:\n",
    "    # [a, b, c]\n",
    "    # [d, e, f]\n",
    "    #\n",
    "    # [a, b, c] is an input example. (context_len = W = 3)\n",
    "    # There are two batches [a, b, c] and [d, e, f] (B = 2)\n",
    "    # a, b, c should be integers (each representing one possible token). a, b, c should belong in [0, dict_size)\n",
    "    def __init__(self, dict_size, context_window_size, embedding_dimensions, num_heads, block_count):\n",
    "        super(CustomTransformer, self).__init__()\n",
    "        self.context_window_size = context_window_size\n",
    "        self.token_embedding = nn.Embedding(dict_size, embedding_dimensions, device=device)\n",
    "        self.position_embedding = nn.Embedding(context_window_size, embedding_dimensions, device=device)\n",
    "        self.decoder = nn.Linear(embedding_dimensions, dict_size, device=device)\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            *[Block(context_window_size, embedding_dimensions, num_heads) for _ in range(0, block_count)]\n",
    "        )\n",
    "\n",
    "    def embed(self, input, spatial = False):\n",
    "        emb = self.token_embedding(input)\n",
    "        if (spatial):\n",
    "            return emb + self.position_embedding(torch.arange(0, self.context_window_size, device=device))\n",
    "\n",
    "        return emb\n",
    "\n",
    "    # Raw input is a tesnor of (B, W). On CPU. It should have already mapped tokens to integer.\n",
    "    def forward(self, raw_input, targets):\n",
    "        if(raw_input.device != device):\n",
    "            raw_input = raw_input.to(device)\n",
    "        input = self.embed(raw_input, True)\n",
    "        logits = self.network(input)\n",
    "        logits = self.decoder(logits)\n",
    "        if (targets != None):\n",
    "            if(targets.device != device):\n",
    "                targets = targets.to(device)\n",
    "            logits_1d = logits.view(logits.shape[0] * logits.shape[1], logits.shape[2])\n",
    "            targets = targets.view(logits_1d.shape[0])\n",
    "            loss = F.cross_entropy(logits_1d, targets)\n",
    "        else:\n",
    "            loss = None\n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, context_len):\n",
    "        self.data = data\n",
    "        self.context_len = context_len\n",
    "\n",
    "    # ABCDE for context len of 1 has 4 examples: (A, B), (B, C), (C, D), (D, E)\n",
    "    # for context len 2 has examples 3 (AB, C), (BC, D), (CD, E)\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.context_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx : idx + self.context_len], device = device), torch.tensor(self.data[idx + 1 :idx + self.context_len + 1], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DELIMITER = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subfolder_0/example_0.json\n",
      "1\n",
      "subfolder_0/example_1.json\n",
      "2\n",
      "subfolder_0/example_2.json\n",
      "3\n",
      "subfolder_0/example_3.json\n",
      "4\n",
      "subfolder_0/example_4.json\n",
      "5\n",
      "subfolder_0/example_5.json\n",
      "6\n",
      "subfolder_0/example_6.json\n",
      "7\n",
      "subfolder_0/example_7.json\n",
      "8\n",
      "subfolder_0/example_8.json\n",
      "9\n",
      "subfolder_0/example_9.json\n",
      "10\n",
      "subfolder_0/example_10.json\n",
      "11\n",
      "subfolder_0/example_11.json\n",
      "12\n",
      "subfolder_0/example_12.json\n",
      "13\n",
      "subfolder_0/example_13.json\n",
      "14\n",
      "subfolder_0/example_14.json\n",
      "15\n",
      "subfolder_0/example_15.json\n",
      "16\n",
      "subfolder_0/example_16.json\n",
      "17\n",
      "subfolder_0/example_17.json\n",
      "18\n",
      "subfolder_0/example_18.json\n",
      "19\n",
      "subfolder_0/example_19.json\n",
      "20\n",
      "subfolder_0/example_20.json\n",
      "21\n",
      "subfolder_0/example_21.json\n",
      "22\n",
      "subfolder_0/example_22.json\n",
      "23\n",
      "subfolder_0/example_23.json\n",
      "24\n",
      "subfolder_0/example_24.json\n",
      "25\n",
      "subfolder_0/example_25.json\n",
      "26\n",
      "subfolder_0/example_26.json\n",
      "27\n",
      "subfolder_0/example_27.json\n",
      "28\n",
      "subfolder_0/example_28.json\n",
      "29\n",
      "subfolder_0/example_29.json\n",
      "30\n",
      "subfolder_0/example_30.json\n",
      "31\n",
      "subfolder_0/example_31.json\n",
      "32\n",
      "subfolder_0/example_32.json\n",
      "33\n",
      "subfolder_0/example_33.json\n",
      "34\n",
      "subfolder_0/example_34.json\n",
      "35\n",
      "subfolder_0/example_35.json\n",
      "36\n",
      "subfolder_0/example_36.json\n",
      "37\n",
      "subfolder_0/example_37.json\n",
      "38\n",
      "subfolder_0/example_38.json\n",
      "39\n",
      "subfolder_0/example_39.json\n",
      "40\n",
      "subfolder_0/example_40.json\n",
      "41\n",
      "subfolder_0/example_41.json\n",
      "42\n",
      "subfolder_0/example_42.json\n",
      "43\n",
      "subfolder_0/example_43.json\n",
      "44\n",
      "subfolder_0/example_44.json\n",
      "45\n",
      "subfolder_0/example_45.json\n",
      "46\n",
      "subfolder_0/example_46.json\n",
      "47\n",
      "subfolder_0/example_47.json\n",
      "48\n",
      "subfolder_0/example_48.json\n",
      "49\n",
      "subfolder_0/example_49.json\n",
      "50\n",
      "subfolder_0/example_50.json\n",
      "51\n",
      "subfolder_0/example_51.json\n",
      "52\n",
      "subfolder_0/example_52.json\n",
      "53\n",
      "subfolder_0/example_53.json\n",
      "54\n",
      "subfolder_0/example_54.json\n",
      "55\n",
      "subfolder_0/example_55.json\n",
      "56\n",
      "subfolder_0/example_56.json\n",
      "57\n",
      "subfolder_0/example_57.json\n",
      "58\n",
      "subfolder_0/example_58.json\n",
      "59\n",
      "subfolder_0/example_59.json\n",
      "60\n",
      "subfolder_0/example_60.json\n",
      "61\n",
      "subfolder_0/example_61.json\n",
      "62\n",
      "subfolder_0/example_62.json\n",
      "63\n",
      "subfolder_0/example_63.json\n",
      "64\n",
      "subfolder_0/example_64.json\n",
      "65\n",
      "subfolder_0/example_65.json\n",
      "66\n",
      "subfolder_0/example_66.json\n",
      "67\n",
      "subfolder_0/example_67.json\n",
      "68\n",
      "subfolder_0/example_68.json\n",
      "69\n",
      "subfolder_0/example_69.json\n",
      "70\n",
      "subfolder_0/example_70.json\n",
      "71\n",
      "subfolder_0/example_71.json\n",
      "72\n",
      "subfolder_0/example_72.json\n",
      "73\n",
      "subfolder_0/example_73.json\n",
      "74\n",
      "subfolder_0/example_74.json\n",
      "75\n",
      "subfolder_0/example_75.json\n",
      "76\n",
      "subfolder_0/example_76.json\n",
      "77\n",
      "subfolder_0/example_77.json\n",
      "78\n",
      "subfolder_0/example_78.json\n",
      "79\n",
      "subfolder_0/example_79.json\n",
      "80\n",
      "subfolder_0/example_80.json\n",
      "81\n",
      "subfolder_0/example_81.json\n",
      "82\n",
      "subfolder_0/example_82.json\n",
      "83\n",
      "subfolder_0/example_83.json\n",
      "84\n",
      "subfolder_0/example_84.json\n",
      "85\n",
      "subfolder_0/example_85.json\n",
      "86\n",
      "subfolder_0/example_86.json\n",
      "87\n",
      "subfolder_0/example_87.json\n",
      "88\n",
      "subfolder_0/example_88.json\n",
      "89\n",
      "subfolder_0/example_89.json\n",
      "90\n",
      "subfolder_0/example_90.json\n",
      "91\n",
      "subfolder_0/example_91.json\n",
      "92\n",
      "subfolder_0/example_92.json\n",
      "93\n",
      "subfolder_0/example_93.json\n",
      "94\n",
      "subfolder_0/example_94.json\n",
      "95\n",
      "subfolder_0/example_95.json\n",
      "96\n",
      "subfolder_0/example_96.json\n",
      "97\n",
      "subfolder_0/example_97.json\n",
      "98\n",
      "subfolder_0/example_98.json\n",
      "99\n",
      "subfolder_0/example_99.json\n",
      "100\n",
      "subfolder_0/example_100.json\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "import coDesc_parser\n",
    "\n",
    "res = coDesc_parser.fragment_dataset(\"../data/CoDesc/CoDesc.json\", \"../data/CoDesc/fragmented\", limit=100)\n",
    "print(res)\n",
    "#coDesc_parser.fragmented_files_to_txt_file(range(90), \"../data/CoDesc/fragmented\", DELIMITER, \"train.txt\")\n",
    "#coDesc_parser.fragmented_files_to_txt_file(range(90, 100), \"../data/CoDesc/fragmented\", DELIMITER, \"test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/CoDesc/fragmented/train.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtiktoken\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_educational\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m tiktoken\u001b[38;5;241m.\u001b[39mget_encoding(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcl100k_base\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/CoDesc/fragmented/train.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      6\u001b[0m     train \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/CoDesc/fragmented/test.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/CoDesc/fragmented/train.txt'"
     ]
    }
   ],
   "source": [
    "from tiktoken._educational import *\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "with open(\"../data/CoDesc/fragmented/train.txt\", \"r\") as f:\n",
    "    train = f.read()\n",
    "\n",
    "with open(\"../data/CoDesc/fragmented/test.txt\", \"r\") as f:\n",
    "    test = f.read()\n",
    "\n",
    "train_enc = tokenizer.encode(train)\n",
    "test_enc = tokenizer.encode(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_LEN = 512\n",
    "BLOCK_COUNT = 2\n",
    "EMBED_DIM = 256\n",
    "NUM_HEADS = 8\n",
    "LEARNING_RATE = 1e-2\n",
    "BATCH_COUNT = 8\n",
    "ITERATIONS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52625333\n"
     ]
    }
   ],
   "source": [
    "transformer = CustomTransformer(tokenizer.n_vocab, CONTEXT_LEN, EMBED_DIM, NUM_HEADS, BLOCK_COUNT)\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(sum(p.numel() for p in transformer.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete(ctx, new_len):\n",
    "    res = [x for x in ctx]\n",
    "    \n",
    "    for _ in range(new_len):\n",
    "        ctx = torch.tensor([res[-CONTEXT_LEN:]])\n",
    "        prob, loss = transformer(ctx, None) # Returns a tensor of size (1, W, EM)\n",
    "        prob = prob.squeeze(0)\n",
    "        prob = torch.softmax(prob, dim=-1) # (1, W, EM)\n",
    "        pred = torch.multinomial(prob, 1) # (1, W, 1)\n",
    "        res.append(pred[-1, 0].item())\n",
    "    return tokenizer.decode(res[-new_len:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 Loss: 11.547046661376953\n"
     ]
    }
   ],
   "source": [
    "loss_history = []\n",
    "history = []\n",
    "loss_avg_block_size = 2\n",
    "\n",
    "train_dataset = TextDataset(train_enc, CONTEXT_LEN)\n",
    "train_loader = DataLoader(train_dataset, BATCH_COUNT, shuffle=True)\n",
    "# Prefetch the first batch\n",
    "#train_in, train_target = get_batches(train_enc, BATCH_COUNT, CONTEXT_LEN)\n",
    "\n",
    "i = 0\n",
    "for current_train_in, current_train_target in train_loader:\n",
    "    # Process the current batch\n",
    "    logits, loss = transformer(current_train_in, current_train_target)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    history.append(loss.item())\n",
    "    if (len(history) >= loss_avg_block_size):\n",
    "        loss_history.append(torch.tensor(history).mean().item())\n",
    "        history = []\n",
    "        print (f\"Iteration {i} Loss: {loss_history[-1]}\")\n",
    "    i += 1\n",
    "\n",
    "    if (i >= ITERATIONS):\n",
    "        break\n",
    "\n",
    "if (len(history) > 0):\n",
    "    loss_history.append(torch.tensor(history).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(loss_history * loss_avg_block_size) + 1, loss_avg_block_size), loss_history)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss History')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________SAMPLED_________________________:\n",
      " directExecutor() cannot throw RejectedExecutionException\n",
      "      return delegate;\n",
      "    }\n",
      "    return new Executor() {\n",
      "      boolean thrownFromDelegate = true;\n",
      "\n",
      "      @Override\n",
      "      public void execute(final Runnable command) {\n",
      "        try {\n",
      "          delegate.execute(\n",
      "              new Runnable() {\n",
      "                @Override\n",
      "                public void run() {\n",
      "                  thrownFromDelegate = false;\n",
      "                  command.run();\n",
      "                }\n",
      "              });\n",
      "        } catch (RejectedExecutionException e) {\n",
      "          if (thrownFromDelegate) {\n",
      "            // wrap exception?\n",
      "            future.setException(e);\n",
      "          }\n",
      "          // otherwise it must have been thrown from a transitive call and the delegate runnable\n",
      "          // should have handled it.\n",
      "        }\n",
      "      }\n",
      "    };\n",
      "  }\n",
      "public Writer openBufferedStream() throws IOException {\n",
      "    Writer writer = openStream();\n",
      "    return (writer instanceof BufferedWriter)\n",
      "        ? (BufferedWriter) writer\n",
      "        : new BufferedWriter(writer);\n",
      "  }\n",
      "public void write(CharSequence charSequence) throws IOException {\n",
      "    checkNotNull(charSequence);\n",
      "\n",
      "    Closer closer = Closer.create();\n",
      "    try {\n",
      "      Writer out = closer.register(openStream());\n",
      "      out.append(charSequence);\n",
      "      out.flush(); // https://code.google.com/p/guava-libraries/issues/detail?id=1330\n",
      "    } catch (Throwable e) {\n",
      "      throw closer.rethrow(e);\n",
      "    } finally {\n",
      "      closer.close();\n",
      "    }\n",
      "  }\n",
      "public void writeLines(Iterable<? extends CharSequence> lines, String lineSeparator)\n",
      "      throws IOException {\n",
      "    writeLines(lines.iterator(), lineSeparator);\n",
      "  }\n",
      "@Beta\n",
      "  public void writeLines(Stream<? extends CharSequence> lines) throws IOException {\n",
      "    writeLines(lines, System.getProperty(\"line.separator\"));\n",
      "  }\n",
      "@Beta\n",
      "  public void writeLines(Stream<? extends CharSequence> lines, String lineSeparator)\n",
      "      throws IOException {\n",
      "    writeLines(lines.iterator(), lineSeparator);\n",
      "  }\n",
      "public <X extends Exception> RuntimeException rethrow(Throwable e, Class<X> declaredType)\n",
      "      throws IOException, X {\n",
      "    checkNotNull(e);\n",
      "    thrown = e;\n",
      "    Throwables.propagateIfPossible(e, IOException.class);\n",
      "    Throwables.propagateIfPossible(e, declaredType);\n",
      "    throw new RuntimeException(e);\n",
      "  }\n",
      "public <X1 extends Exception, X2 extends Exception> RuntimeException rethrow(\n",
      "      Throwable e, Class<X1> declaredType1, Class<X2> declaredType2) throws IOException, X1, X2 {\n",
      "    checkNotNull(e);\n",
      "    thrown = e;\n",
      "    Throwables.propagateIfPossible(e, IOException.class);\n",
      "    Throwables.propagate\n",
      "_________________________PREDICTED_______________________:\n",
      ":\t\t\t\t\t\t\tProfileReceivedï¿½ forfe '(G.isPublicDate loadDatarepo;\n",
      " else((\n"
     ]
    }
   ],
   "source": [
    "start = torch.randint(0, len(test_enc) - CONTEXT_LEN, (1,)).item()\n",
    "sampled_txt = test_enc[start:start+CONTEXT_LEN]\n",
    "print(\"_________________________SAMPLED_________________________:\")\n",
    "print(tokenizer.decode(sampled_txt))\n",
    "print(\"_________________________PREDICTED_______________________:\")\n",
    "print(complete(sampled_txt, 16))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
